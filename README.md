# llama_cpp_java

Ссылка на статью на хабре со всеми ссылками:
https://habr.com/ru/articles/743110/

В данной ветке, реализована сборка контейнера с приложением, к которому можно обращаться по рест,
модели меняются в src/main.py при пересборке.

Реализация модуля на java для общения с этим контейнером:
https://github.com/j0schihatake/llama_cpp_python_Java

То есть конечное приложение обращается к java модулю, 
но может и без него напрямую только ответ будет не мнгоновенным тогда.
в Java модуле можно реализовать систему запоминания чатов
и остальные фишки других оболочек.

Порядок:
1. получить полное название модели которую вы хотите использовать
2. положить ее в model папку в корне или в любом другом месте но тогда в команде запуска 
контейнера не забудьте указать правильный volume к папке где она лежит(нужно например если ее положили на ssd)
3. далее выполнить команды в dockerfile внизу по порядку, attach не нужно выполнять, он для дебага. 